# Tool Integration Guide

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: Agent ä½¿ç”¨ï¼ˆè‡ªåŠ¨é¢„åŠ è½½ï¼‰

```python
from agent.mm_agent import MultimodalAgent

# Agent è‡ªåŠ¨é¢„åŠ è½½ tool_bank ä¸­çš„æ¨¡å‹ï¼ˆé»˜è®¤æ£€æµ‹æ‰€æœ‰ GPUï¼‰
agent = MultimodalAgent(
    tool_bank=["ocr", "localize_objects"],
    model_name="qwen2.5-vl-72b-instruct"
)

# æŒ‡å®š GPU åˆ†é…
agent = MultimodalAgent(
    tool_bank=["ocr", "localize_objects"],
    model_name="qwen2.5-vl-72b-instruct",
    preload_devices=["cuda:0", "cuda:1"]  # å¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
)

# ä½¿ç”¨å·¥å…·ï¼ˆæ— å»¶è¿Ÿï¼Œæ¨¡å‹å·²é¢„åŠ è½½ï¼‰
result = await agent.act(query="è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—", images=["test.jpg"])
```

### æ–¹å¼ 2: ç‹¬ç«‹æµ‹è¯•å·¥å…·

```python
from tool import TOOL_REGISTRY
from pathlib import Path

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR = Path("test_outputs")
OUTPUT_DIR.mkdir(exist_ok=True)

# è°ƒç”¨å·¥å…·ï¼ˆé¦–æ¬¡è°ƒç”¨è‡ªåŠ¨åŠ è½½æ¨¡å‹ï¼‰
tool = TOOL_REGISTRY["localize_objects"]()
result = tool.call({"image": "test.jpg", "objects": ["dog"]})

# æ‰‹åŠ¨ä¿å­˜å¤šæ¨¡æ€è¾“å‡ºï¼ˆPIL Imageï¼‰
if "output_image" in result:
    from PIL import Image
    if isinstance(result["output_image"], Image.Image):
        result["output_image"].save(OUTPUT_DIR / "output.png")
```

### æ–¹å¼ 3: æ‰‹åŠ¨é¢„åŠ è½½

```python
from tool.model_cache import preload_tools

# é¢„åŠ è½½æŒ‡å®šå·¥å…·åˆ°æŒ‡å®š GPU
preload_tools(
    tool_bank=["ocr", "localize_objects"],
    devices=["cuda:0", "cuda:1"]  # è½®æµåˆ†é…
)

# ä¹‹ååˆ›å»ºçš„å·¥å…·å®ä¾‹ä¼šå¤ç”¨é¢„åŠ è½½çš„æ¨¡å‹
```

## 1. éæ¨¡å‹å·¥å…· (Non-Model Tool)

é€‚ç”¨äºï¼šè®¡ç®—å™¨ã€å›¾åƒå¤„ç†ã€API è°ƒç”¨ç­‰ä¸éœ€è¦åŠ è½½æ¨¡å‹çš„å·¥å…·ã€‚

```python
# tool/my_tool.py
import json
from typing import Union, Dict
from tool.base_tool import BasicTool, register_tool


@register_tool(name="my_tool")
class MyTool(BasicTool):
    name = "my_tool"
    description_en = "English description"
    description_zh = "ä¸­æ–‡æè¿°"
    parameters = {
        "type": "object",
        "properties": {
            "param1": {"type": "string", "description": "å‚æ•°è¯´æ˜"},
        },
        "required": ["param1"]
    }
    example = '{"param1": "value"}'

    def call(self, params: Union[str, Dict]) -> str:
        p = self.parse_params(params)
        
        # å®ç°é€»è¾‘
        result = process(p["param1"])
        
        return json.dumps({"success": True, "result": result})
```

## 2. æ¨¡å‹å·¥å…· (Model-Based Tool)

é€‚ç”¨äºï¼šOCRã€ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²ç­‰éœ€è¦åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹çš„å·¥å…·ã€‚

```python
# tool/ocr_tool.py
import json
from typing import Union, Dict
from tool.base_tool import ModelBasedTool, register_tool


@register_tool(name="ocr")
class OCRTool(ModelBasedTool):
    name = "ocr"
    model_id = "ocr"
    
    description_en = "Extract text from image"
    description_zh = "ä»å›¾åƒä¸­æå–æ–‡å­—"
    parameters = {
        "type": "object",
        "properties": {
            "image": {"type": "string", "description": "å›¾åƒè·¯å¾„"},
        },
        "required": ["image"]
    }
    example = '{"image": "image-0"}'

    def load_model(self, device: str):
        """åŠ è½½æ¨¡å‹å¹¶è®¾ç½®åˆ° self.model"""
        import easyocr
        self.model = easyocr.Reader(["en"], gpu=device.startswith("cuda"))
        self.device = device
        self.is_loaded = True

    def _call_impl(self, params: Union[str, Dict]) -> str:
        """å®ç°å·¥å…·é€»è¾‘"""
        p = self.parse_params(params)
        result = self.model.readtext(p["image"])
        return json.dumps({"success": True, "text": result})
```

**çº¦å®š**ï¼šä¸»æ¨¡å‹ç»Ÿä¸€å­˜å‚¨åœ¨ `self.model`ï¼Œè¾…åŠ©ç»„ä»¶ï¼ˆå¦‚ preprocess, tokenizerï¼‰å¯ä»¥è‡ªç”±å‘½åã€‚

## 3. å·¥å…·è¿”å›æ ¼å¼è§„èŒƒ

### ç»Ÿä¸€è¿”å›æ ¼å¼ï¼šDict

**æ‰€æœ‰å·¥å…·å¿…é¡»è¿”å› `Dict` ç±»å‹**ï¼ŒåŒ…å«ä»¥ä¸‹æ ‡å‡†å­—æ®µï¼š

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|------|------|------|------|
| `error` | `str` | å¤±è´¥æ—¶å¿…éœ€ | é”™è¯¯ä¿¡æ¯ |
| æ•°æ®å­—æ®µ | Any | æˆåŠŸæ—¶ | å·¥å…·è¿”å›çš„ä¸šåŠ¡æ•°æ®ï¼ˆè¯­ä¹‰åŒ–å‘½åï¼‰ |
| `output_image` | `PIL.Image` æˆ– `str` | å¯é€‰ | å›¾åƒè¾“å‡ºï¼ˆè§¦å‘å¤šæ¨¡æ€å¤„ç†ï¼‰ |
| `output_video` | `str` | å¯é€‰ | è§†é¢‘è¾“å‡ºï¼ˆè§¦å‘å¤šæ¨¡æ€å¤„ç†ï¼‰ |

**å…³é”®åŸåˆ™ï¼š**
- âœ… **æˆåŠŸæ—¶**ï¼šåªè¿”å›æ•°æ®å­—æ®µï¼Œæ—  `success` å­—æ®µ
- âŒ **å¤±è´¥æ—¶**ï¼šåªè¿”å› `{"error": "..."}`
- ğŸ¯ **æ•°æ®å­—æ®µå‘½å**ï¼šè¯­ä¹‰åŒ–ä¸”ç®€æ´ï¼ˆå¦‚ `result`, `depth`, `objects`, `text`ï¼‰
- ğŸš« **é¿å…å†—ä½™**ï¼šä¸è¿”å›è¾“å…¥å‚æ•°çš„echoï¼ˆå¦‚ `expression`, `mode`, `query`ï¼‰

### åŸºæœ¬è¿”å›ç¤ºä¾‹

#### æˆåŠŸè¿”å›

```python
# æ•°æ®å·¥å…·
@register_tool(name="calculator")
class CalculatorTool(BasicTool):
    def call(self, params):
        result = eval(expression)
        return {
            "success": True,
            "result": result,  # ä¸šåŠ¡æ•°æ®
            "expression": expression
        }

# å›¾åƒå·¥å…·
@register_tool(name="crop")
class CropTool(BasicTool):
    def call(self, params):
        cropped = image.crop(bbox)
        return {
            "success": True,
            "output_image": cropped,  # PIL.Image å¯¹è±¡ï¼ˆè§¦å‘å¤šæ¨¡æ€å¤„ç†ï¼‰
            "original_size": [W, H],
            "cropped_size": [400, 300]
        }

# è§†é¢‘å·¥å…·
@register_tool(name="video_process")
class VideoProcessTool(BasicTool):
    def call(self, params):
        output_path = process_video(...)
        return {
            "success": True,
            "output_video": output_path,  # æ–‡ä»¶è·¯å¾„ï¼ˆè§¦å‘å¤šæ¨¡æ€å¤„ç†ï¼‰
            "duration": 10.5
        }
```

#### å¤±è´¥è¿”å›

```python
# æ‰€æœ‰å·¥å…·çš„é”™è¯¯è¿”å›æ ¼å¼ç»Ÿä¸€
def call(self, params):
    if validation_failed:
        return {
            "success": False,
            "error": "Invalid parameters: ..."
        }
    
    try:
        # ... å¤„ç†é€»è¾‘ ...
    except Exception as e:
        return {
            "success": False,
            "error": f"Error processing: {str(e)}"
        }
```

### Agent è‡ªåŠ¨å¤„ç†

#### **çº¯æ•°æ®å·¥å…·**

Agent å°†æ•°æ®å±•å¼€æˆè‡ªç„¶è¯­è¨€å¥å­ä¼ ç»™ LLMï¼š

```
# calculator å·¥å…·è¿”å›ï¼š{"result": 56088}
Observation: Result: 56088

# get_objects å·¥å…·è¿”å›ï¼š{"objects": ["cat", "dog", "tree"]}
Observation: Detected objects: cat, dog, tree

# ocr å·¥å…·è¿”å›ï¼š{"text": "Hello World"}
Observation: Extracted text: Hello World

# estimate_region_depth å·¥å…·è¿”å›ï¼š{"depth": 0.5432}
Observation: Estimated depth: 0.5432

# é”™è¯¯æƒ…å†µè¿”å›ï¼š{"error": "bbox values must be between 0 and 1"}
Observation: bbox values must be between 0 and 1
```

#### **çº¯å›¾åƒå·¥å…·**

Agent ä½¿ç”¨ Memory ç”Ÿæˆçš„æè¿°ï¼š

```
# crop å·¥å…·è¿”å›ï¼š{"output_image": <PIL.Image>, "original_size": [800, 600], "cropped_size": [400, 300]}
Observation: saved as img_1: Cropped img_0 at bbox [0.25, 0.25, 0.75, 0.75]

# zoom_in å·¥å…·è¿”å›ï¼š{"output_image": <PIL.Image>, "original_size": [800, 600], "zoomed_size": [1200, 900]}
Observation: saved as img_2: Zoomed in img_0 at bbox [0.5, 0.5, 0.7, 0.7] with factor 2.0
```

#### **å›¾åƒ+æ•°æ®å·¥å…·**

Agent ç»“åˆ Memory æè¿°å’Œä¸šåŠ¡æ•°æ®ï¼š

```
# localize_objects å·¥å…·è¿”å›ï¼š{"output_image": <PIL.Image>, "regions": [{"bbox": [...], "label": "dog"}, ...]}
Observation: saved as img_3: Localized regions on img_0. {"regions": [{"bbox": [0.1, 0.2, 0.3, 0.4], "label": "dog"}, {"bbox": [0.5, 0.6, 0.7, 0.8], "label": "cat"}]}

# detect_faces å·¥å…·è¿”å›ï¼š{"output_image": <PIL.Image>, "regions": [{"bbox": [...], "label": "face"}, ...]}
Observation: saved as img_4: Detected faces on img_0. {"regions": [{"bbox": [0.2, 0.1, 0.4, 0.5], "label": "face"}]}
```

#### **ç›¸ä¼¼åº¦å·¥å…·**

Agent å±•å¼€æˆç»“æ„åŒ–å¥å­ï¼š

```
# get_image2images_similarity å·¥å…·è¿”å›ï¼š{"similarity": [0.85, 0.72, 0.91], "best_image_index": 2}
Observation: Similarity scores: [0.85, 0.72, 0.91], best match at index 2
```

#### **å¤„ç†æµç¨‹**

1. **Memory ä¿å­˜**ï¼šæ£€æµ‹åˆ° `output_image`/`output_video` æ—¶ï¼ŒMemory è‡ªåŠ¨ä¿å­˜åˆ° `memory/tasks/{task_id}/` å¹¶ç”Ÿæˆ IDï¼ˆå¦‚ `img_0`ï¼‰
2. **æè¿°ç”Ÿæˆ**ï¼šMemory æ ¹æ®å·¥å…·ç±»å‹å’Œå‚æ•°ç”Ÿæˆæè¿°ï¼ˆå¦‚ "Cropped img_0 at bbox [...]"ï¼‰
3. **æ•°æ®ç»„åˆ**ï¼šAgent å°†æè¿°ä¸å…¶ä»–ä¸šåŠ¡æ•°æ®ï¼ˆå¦‚ `regions`ï¼‰ç»„åˆä¼ ç»™ LLM

## 4. æµ‹è¯•å·¥å…·

åœ¨ `test_tools.py` æ·»åŠ æµ‹è¯•ï¼š

```python
async def test():
    # æµ‹è¯•å›¾åƒå·¥å…·
    r = await TOOL_REGISTRY["localize_objects"]().call_async({
        "image": "test.jpg", 
        "objects": ["dog"]
    })
    # ä¿å­˜å¤šæ¨¡æ€è¾“å‡ºï¼ˆè‡ªåŠ¨æ£€æµ‹ output_image æˆ– output_videoï¼‰
    r = save_multimodal_output(r, "localize_objects")
    print(f"localize_objects: {r}")
    
    # æµ‹è¯•è§†é¢‘å·¥å…·ï¼ˆæœªæ¥ï¼‰
    # r = await TOOL_REGISTRY["video_process"]().call_async({...})
    # r = save_multimodal_output(r, "video_process")  # è‡ªåŠ¨ä¿å­˜è§†é¢‘
```

è¿è¡Œï¼š`python test_tools.py`

**è¾“å‡ºè¯´æ˜**ï¼š
- éæ¨¡å‹å·¥å…·ï¼šè¿”å›ç»“æœï¼ˆJSON string æˆ– dictï¼‰
- å›¾åƒå·¥å…·ï¼šè¿”å› dictï¼ŒåŒ…å« `output_image`ï¼ˆPIL.Image å¯¹è±¡æˆ–è·¯å¾„ï¼‰
- è§†é¢‘å·¥å…·ï¼šè¿”å› dictï¼ŒåŒ…å« `output_video`ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
- `save_multimodal_output()` è‡ªåŠ¨ä¿å­˜åˆ° `test_outputs/` ç›®å½•

---

## æ³¨æ„äº‹é¡¹

### å¿…é¡»éµå®ˆ

1. **è¿”å›æ ¼å¼**ï¼šè¿”å› JSON å­—ç¬¦ä¸²ï¼ŒæˆåŠŸ `{"success": True, ...}`ï¼Œå¤±è´¥ `{"error": "é”™è¯¯ä¿¡æ¯"}`
2. **å‚æ•°éªŒè¯**ï¼šä½¿ç”¨ `self.parse_params(params)` è§£æå’ŒéªŒè¯å‚æ•°
3. **å¿…é¡»æœ‰ example**ï¼š`example` å±æ€§ç”¨äº prompt ä¸­å±•ç¤ºå·¥å…·ç”¨æ³•ï¼ŒAgent ä¾èµ–å®ƒæ¥å­¦ä¹ å¦‚ä½•è°ƒç”¨å·¥å…·

### æ¨¡å‹å·¥å…·æ³¨æ„äº‹é¡¹

1. **ä¸»æ¨¡å‹ç»Ÿä¸€å‘½å `self.model`**ï¼šç¼“å­˜å’Œå…±äº«åŸºäºæ­¤çº¦å®š

2. **è¾…åŠ©ç»„ä»¶è‡ªç”±å‘½å**ï¼šå¦‚ `self.preprocess`, `self.tokenizer` ç­‰

3. **å®ç° `_call_impl` è€Œé `call`**ï¼š`call` è‡ªåŠ¨å¤„ç†æ¨¡å‹åŠ è½½å’Œç¼“å­˜

4. **GPU è‡ªåŠ¨é€‰æ‹©**ï¼šä¸æŒ‡å®š device æ—¶ï¼Œç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©å¯ç”¨ GPU

### å‘½åè§„èŒƒ

| ç±»å‹ | è§„èŒƒ | ç¤ºä¾‹ |
|------|------|------|
| æ–‡ä»¶å | `snake_case_tool.py` | `crop_tool.py`, `ocr_tool.py` |
| ç±»å | `PascalCase` + `Tool` åç¼€ | `CropTool`, `OCRTool` |
| å·¥å…·å (name) | `snake_case` | `crop`, `ocr`, `solve_math` |
| å˜é‡/å‡½æ•° | `snake_case` | `output_path`, `load_model` |
| å¸¸é‡ | `UPPER_SNAKE_CASE` | `OCR_MODEL_PATH` |

### ä»£ç é£æ ¼

- ä¿æŒç®€æ´ï¼Œé¿å…å†—ä½™ä»£ç ï¼Œè‹±æ–‡æ³¨é‡Š
- é”™è¯¯ç›´æ¥è¿”å› `{"error": "..."}`ï¼Œä¸è¦æŠ›å¼‚å¸¸
- ä½¿ç”¨ç±»å‹æ³¨è§£ `Union[str, Dict]`
